{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiteHack 2022 Flair","provenance":[{"file_id":"1PRDUQZNozu_J5gveSQsIGiTy9XWtMdK_","timestamp":1642255955519}],"collapsed_sections":[],"authorship_tag":"ABX9TyNm1E5efNV6flq2cEp36fcH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"noosVbBNYONS","executionInfo":{"status":"ok","timestamp":1642257982178,"user_tz":-60,"elapsed":49551,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"10154e18-e68d-4d09-b743-bfd57e6f2f73"},"source":["!pip install flair"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting flair\n","  Downloading flair-0.10-py3-none-any.whl (322 kB)\n","\u001b[K     |████████████████████████████████| 322 kB 5.2 MB/s \n","\u001b[?25hCollecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[K     |████████████████████████████████| 981 kB 46.1 MB/s \n","\u001b[?25hCollecting sqlitedict>=1.6.0\n","  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n","Collecting segtok>=1.5.7\n","  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n","Collecting transformers>=4.0.0\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 42.7 MB/s \n","\u001b[?25hCollecting conllu>=4.0\n","  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n","Collecting deprecated>=1.2.4\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Collecting sentencepiece==0.1.95\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 25.4 MB/s \n","\u001b[?25hCollecting gdown==3.12.2\n","  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n","Collecting more-itertools~=8.8.0\n","  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n","\u001b[K     |████████████████████████████████| 48 kB 5.2 MB/s \n","\u001b[?25hCollecting konoha<5.0.0,>=4.0.0\n","  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n","Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.10.0+cu111)\n","Collecting ftfy\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[K     |████████████████████████████████| 64 kB 3.0 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.2)\n","Collecting wikipedia-api\n","  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n","Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n","Collecting janome\n","  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n","\u001b[K     |████████████████████████████████| 19.7 MB 1.2 MB/s \n","\u001b[?25hCollecting bpemb>=0.3.2\n","  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n","Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.62.3)\n","Collecting mpld3==0.3\n","  Downloading mpld3-0.3.tar.gz (788 kB)\n","\u001b[K     |████████████████████████████████| 788 kB 49.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.4.2)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.19.5)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.13.3)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (5.2.1)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n","Collecting overrides<4.0.0,>=3.0.0\n","  Downloading overrides-3.1.0.tar.gz (11 kB)\n","Collecting requests\n","  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting importlib-metadata<4.0.0,>=3.7.0\n","  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.10.0.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (3.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.0.10)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (3.0.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 52.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 40.6 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 52.4 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.7.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n","Building wheels for collected packages: gdown, mpld3, overrides, sqlitedict, ftfy, langdetect, wikipedia-api\n","  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9704 sha256=c73281d49af8e34ca321f9f715420e8ca9ec6de409b65fbf8fa32bc09baac6bb\n","  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n","  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=c2457dc599a1e25ea107e20d011f26ccbbf1325c7ab5281ceb594276ff2a27ae\n","  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=72a54e77fbf7e2b129feea8766602ef3a8a6bc48f0372fa4fb9ee258c4b4776c\n","  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14393 sha256=5f6f3185634722afac048c300093c0c9c5bcaea9d5efd015a44d346d2578671a\n","  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=ee446e68c0fd1c213c2dcc21feb5b901f5c02e584f4ac7d8a214175a262ed937\n","  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=109aca89a9508b9e6ec2ccd9b6339313d0f9033537765c6f4c7bb81efd7f486e\n","  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n","  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=537a55bd9aee951f407bd6bd226fcf8a18330fd2d241f8b746ec6d5ca200c029\n","  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n","Successfully built gdown mpld3 overrides sqlitedict ftfy langdetect wikipedia-api\n","Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, sacremoses, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, mpld3, more-itertools, langdetect, konoha, janome, gdown, ftfy, deprecated, conllu, bpemb, flair\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.10.0\n","    Uninstalling importlib-metadata-4.10.0:\n","      Successfully uninstalled importlib-metadata-4.10.0\n","  Attempting uninstall: more-itertools\n","    Found existing installation: more-itertools 8.12.0\n","    Uninstalling more-itertools-8.12.0:\n","      Successfully uninstalled more-itertools-8.12.0\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 3.6.4\n","    Uninstalling gdown-3.6.4:\n","      Successfully uninstalled gdown-3.6.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.10 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.4.0 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pyyaml-6.0 requests-2.27.1 sacremoses-0.0.47 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 transformers-4.15.0 wikipedia-api-0.5.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["requests"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":90},"id":"tgy5Bx4DYWGd","executionInfo":{"status":"ok","timestamp":1642256820572,"user_tz":-60,"elapsed":44606,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"d295aa2f-077d-4402-8811-f5e4bfd7c71b"},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-f84363e8-a00b-4a14-abc5-b4bbcb149734\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f84363e8-a00b-4a14-abc5-b4bbcb149734\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving stanfordSentimentTreebankRaw.zip to stanfordSentimentTreebankRaw.zip\n","User uploaded file \"stanfordSentimentTreebankRaw.zip\" with length 4771260 bytes\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7SOeuNmHYd12","executionInfo":{"status":"ok","timestamp":1642256936356,"user_tz":-60,"elapsed":261,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"e93f80dd-a406-4e18-9dcb-a6bb1dba5e7a"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample_data  stanfordSentimentTreebankRaw.zip\n"]}]},{"cell_type":"code","source":["!unzip stanfordSentimentTreebankRaw.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmfUkpFsGz0h","executionInfo":{"status":"ok","timestamp":1642256937093,"user_tz":-60,"elapsed":351,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"75dfda55-aeb7-4e92-9465-94d0d6f1ed6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  stanfordSentimentTreebankRaw.zip\n","   creating: stanfordSentimentTreebankRaw/\n","  inflating: stanfordSentimentTreebankRaw/rawscores_exp12.txt  \n","  inflating: stanfordSentimentTreebankRaw/README.txt  \n","  inflating: stanfordSentimentTreebankRaw/sentlex_exp12.txt  \n"]}]},{"cell_type":"code","source":["!ls -l"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10gx1UCgGzrb","executionInfo":{"status":"ok","timestamp":1642256937390,"user_tz":-60,"elapsed":301,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"dd9d63d4-edf8-4a3c-d1bb-35b787d6ac27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 4668\n","drwxr-xr-x 1 root root    4096 Jan  7 14:33 sample_data\n","drwxr-xr-x 2 root root    4096 Oct  9  2013 stanfordSentimentTreebankRaw\n","-rw-r--r-- 1 root root 4771260 Jan 15 14:27 stanfordSentimentTreebankRaw.zip\n"]}]},{"cell_type":"code","source":["!ls stanfordSentimentTreebankRaw"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDrzwnnwGzix","executionInfo":{"status":"ok","timestamp":1642256938312,"user_tz":-60,"elapsed":228,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"8f92c00e-7926-4490-dd45-eaefd38331c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rawscores_exp12.txt  README.txt  sentlex_exp12.txt\n"]}]},{"cell_type":"code","source":["!head stanfordSentimentTreebankRaw/rawscores_exp12.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A4DQmTmGGzSO","executionInfo":{"status":"ok","timestamp":1642256939667,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"92e94e79-ad6b-440f-9203-f1aef4d1566d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0,13,13,13\n","1,13,13,13\n","2,9,13,13\n","3,13,13,13\n","4,10,9,13,13\n","5,16,5,9\n","6,8,11,14\n","7,13,14,15\n","8,1,13,13\n","9,9,13,14\n"]}]},{"cell_type":"code","source":["!head stanfordSentimentTreebankRaw/sentlex_exp12.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJt2HoWzHX-T","executionInfo":{"status":"ok","timestamp":1642256939990,"user_tz":-60,"elapsed":325,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"b2cba6b4-c5d8-4fb9-adac-58ff7630b846"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0,!\n","1,'\n","2,' (\n","3,' ( the cockettes\n","4,' ( the cockettes )\n","5,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable\n","6,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable .\n","7,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable . '\n","8,' a nightmare on elm street\n","9,' a nightmare on elm street '\n"]}]},{"cell_type":"markdown","source":["# Data Processing"],"metadata":{"id":"V6k7ibapHkBx"}},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"JV0BR517Hjq_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scores = pd.read_csv('stanfordSentimentTreebankRaw/rawscores_exp12.txt', names=[\"id\", \"score1\", \"score2\", \"score3\"])\n","texts = pd.read_csv('stanfordSentimentTreebankRaw/sentlex_exp12.txt', names=[\"id\", \"text\"])"],"metadata":{"id":"1rAubO87HjPM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir data"],"metadata":{"id":"VgZi0g4LHjdT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = texts.merge(scores, how='left', on=['id', 'id'])"],"metadata":{"id":"NzJD4mIWIHF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['score'] = (data['score1'] + data['score2'] + data['score3']) / 3"],"metadata":{"id":"cXuKpuOyKCc2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def interval(score):\n","    if score <= 5:\n","        return 'negative'\n","    elif score <= 10:\n","        return 'fairly negative'\n","    elif score <= 15:\n","        return 'neutral'\n","    elif score <= 20:\n","        return 'fairly positive'\n","    else:\n","        return 'positive'\n","\n","data['score'] = data['score'].map(interval)"],"metadata":{"id":"VCBcb_oqK8Lw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = data.drop(labels=['score1', 'score2', 'score3'], axis=1)"],"metadata":{"id":"Eesa5PFxLYS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"29Kx7gNWLox_","executionInfo":{"status":"ok","timestamp":1642257623795,"user_tz":-60,"elapsed":587,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"421812da-f896-4a01-c556-69f3cf277a14"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-ef2d76d0-09d9-4895-acae-7da29434690a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>!</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>'</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>' (</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>' ( the cockettes</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>' ( the cockettes )</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef2d76d0-09d9-4895-acae-7da29434690a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ef2d76d0-09d9-4895-acae-7da29434690a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ef2d76d0-09d9-4895-acae-7da29434690a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   id                 text    score\n","0   0                    !  neutral\n","1   1                    '  neutral\n","2   2                  ' (  neutral\n","3   3    ' ( the cockettes  neutral\n","4   4  ' ( the cockettes )  neutral"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["data.to_csv('data/data.csv', index=None)"],"metadata":{"id":"-OddCQ3VLp1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head data/data.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmuTxg3fTjix","executionInfo":{"status":"ok","timestamp":1642259710942,"user_tz":-60,"elapsed":569,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"beb8481b-d248-4ba2-d343-6fd086ce80a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["id,text,score\n","0,!,neutral\n","1,',neutral\n","2,' (,neutral\n","3,' ( the cockettes,neutral\n","4,' ( the cockettes ),neutral\n","5,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable,fairly negative\n","6,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable .,neutral\n","7,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable . ',neutral\n","8,' a nightmare on elm street,fairly negative\n"]}]},{"cell_type":"code","source":["len(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TTYsP0_UMlOo","executionInfo":{"status":"ok","timestamp":1642258061086,"user_tz":-60,"elapsed":220,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"4ff23f77-7077-4ccb-9a95-46af98b39753"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["239232"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","# copy it there\n","!cp data/data.csv /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZNKHAgaUmXp","executionInfo":{"status":"ok","timestamp":1642260048433,"user_tz":-60,"elapsed":3039,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"3b06926e-e8d8-4bb8-82f9-ffd468fa4e2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!cp data/data.csv data/data-orig.csv"],"metadata":{"id":"k5w2_qVVWGxG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tail -n +2 data/data-orig.csv > data/data.csv"],"metadata":{"id":"JfUpU_KUV6M5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!head data/data.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XblyAIGWN86","executionInfo":{"status":"ok","timestamp":1642260396336,"user_tz":-60,"elapsed":552,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"409b703c-c85f-410a-a7f0-6945dffdf6b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0,!,neutral\n","1,',neutral\n","2,' (,neutral\n","3,' ( the cockettes,neutral\n","4,' ( the cockettes ),neutral\n","5,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable,fairly negative\n","6,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable .,neutral\n","7,' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable . ',neutral\n","8,' a nightmare on elm street,fairly negative\n","9,' a nightmare on elm street ',neutral\n"]}]},{"cell_type":"code","source":["!head -n 100 data/data.csv > data/data-sampled.csv"],"metadata":{"id":"duHF1ZLxW7A-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"4U1NqzN4Gxjb"}},{"cell_type":"markdown","source":["### Reading data"],"metadata":{"id":"NL68PvjuPD4L"}},{"cell_type":"code","metadata":{"id":"fBVua8sOZX8v"},"source":["import flair\n","from flair.data import Corpus, Sentence\n","from flair.datasets import CSVClassificationCorpus\n","from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings\n","from flair.models import TextClassifier\n","from flair.trainers import ModelTrainer"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import nn"],"metadata":{"id":"8ob-KLjSPQyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpoAnXC4awhv"},"source":["import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JJtBY7SwXUIi","executionInfo":{"status":"ok","timestamp":1642260682704,"user_tz":-60,"elapsed":549,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"ac2f7b1f-47a5-48b7-a817-963b12491c4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["data.csv  data-orig.csv  data-sampled.csv\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"icFlYKegZ2JG","executionInfo":{"status":"ok","timestamp":1642260746524,"user_tz":-60,"elapsed":1370,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"052e7fbc-2cc2-4d56-acde-180117e6348c"},"source":["columns = {\n","    0: 'id',\n","    1: 'text',\n","    2: 'label'\n","}\n","\n","data_folder = 'data'\n","\n","corpus: Corpus = CSVClassificationCorpus(data_folder,\n","                                         columns,\n","                                         label_type='label',\n","                                         train_file='data.csv',\n","                                         skip_header=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-15 15:32:26,113 Reading data from data\n","2022-01-15 15:32:26,117 Train: data/data.csv\n","2022-01-15 15:32:26,120 Dev: None\n","2022-01-15 15:32:26,124 Test: None\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"li2s9P1ecRBv","executionInfo":{"status":"ok","timestamp":1642260746524,"user_tz":-60,"elapsed":4,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"4889259d-fc11-4e05-8d32-d29a0da8bcaf"},"source":["len(corpus.train), len(corpus.dev), len(corpus.test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(193777, 21531, 23923)"]},"metadata":{},"execution_count":128}]},{"cell_type":"code","source":["corpus.dev"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msL5bBUFUOZy","executionInfo":{"status":"ok","timestamp":1642260747823,"user_tz":-60,"elapsed":1,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"f9609b2b-3c26-4f8f-e85f-79b854e7e43c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.dataset.Subset at 0x7f9275b67290>"]},"metadata":{},"execution_count":129}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kln_jno0hHiA","executionInfo":{"status":"ok","timestamp":1642260915563,"user_tz":-60,"elapsed":154742,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"4237cd03-9fdf-4437-db9d-9c482ba9c975"},"source":["label_type = 'label'\n","label_dict = corpus.make_label_dictionary(label_type=label_type)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-15 15:32:41,764 Computing label dictionary. Progress:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","100%|██████████| 193777/193777 [02:33<00:00, 1258.81it/s]"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 15:35:16,244 Corpus contains the labels: label (#193777)\n","2022-01-15 15:35:16,245 Created (for label 'label') Dictionary with 6 tags: <unk>, neutral, fairly negative, fairly positive, positive, negative\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["label_dict.item2idx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_nDi1oKFVnVS","executionInfo":{"status":"ok","timestamp":1642260990734,"user_tz":-60,"elapsed":206,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"8a796b0d-5f9f-438b-9955-d76f0444726e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{b'<unk>': 0,\n"," b'fairly negative': 2,\n"," b'fairly positive': 3,\n"," b'negative': 5,\n"," b'neutral': 1,\n"," b'positive': 4}"]},"metadata":{},"execution_count":133}]},{"cell_type":"markdown","source":["### Defining architecture"],"metadata":{"id":"cGL4vP_aPG9I"}},{"cell_type":"code","source":["sent = flair.models.TextClassifier.load('en-sentiment')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxK6Edu3NihW","executionInfo":{"status":"ok","timestamp":1642261039738,"user_tz":-60,"elapsed":2557,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"33321c72-87f6-4ead-bb6d-23439378021c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-01-15 15:37:18,121 loading file /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n"]}]},{"cell_type":"code","source":["sent.label_dictionary = label_dict\n","sent.decoder = nn.Linear(sent.document_embeddings.embedding_length, len(sent.label_dictionary))\n","nn.init.xavier_uniform_(sent.decoder.weight)\n","\n","sent.to('cuda:0')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xerfCI8hPB_e","executionInfo":{"status":"ok","timestamp":1642261162361,"user_tz":-60,"elapsed":273,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"4fcf04a2-50e3-41bb-c3fa-0ba8197d15ae"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TextClassifier(\n","  (loss_function): CrossEntropyLoss()\n","  (document_embeddings): TransformerDocumentEmbeddings(\n","    (model): DistilBertModel(\n","      (embeddings): Embeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (transformer): Transformer(\n","        (layer): ModuleList(\n","          (0): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (1): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (2): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (3): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (4): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (5): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (decoder): Linear(in_features=768, out_features=6, bias=True)\n",")"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","source":["sent.label_dictionary.idx2item"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e6kz8SxSOl51","executionInfo":{"status":"ok","timestamp":1642261040119,"user_tz":-60,"elapsed":2,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"472903c1-2a2d-4c64-b3b7-8b71a049363d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[b'<unk>',\n"," b'neutral',\n"," b'fairly negative',\n"," b'fairly positive',\n"," b'positive',\n"," b'negative']"]},"metadata":{},"execution_count":136}]},{"cell_type":"code","metadata":{"id":"6MKJIO5vjrzh"},"source":["trainer: ModelTrainer = ModelTrainer(sent,\n","                                     corpus)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CLu_Q2PejynF","outputId":"9837073f-8275-4cd1-e0e0-f0e0850c5f20"},"source":["trainer.train('resources/models',\n","              learning_rate=0.1,\n","              mini_batch_size=64,\n","              max_epochs=200,\n","              patience=3,\n","              monitor_test=True,\n","              embeddings_storage_mode='gpu')"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 15:39:32,138 ----------------------------------------------------------------------------------------------------\n","2022-01-15 15:39:32,144 Model: \"TextClassifier(\n","  (loss_function): CrossEntropyLoss()\n","  (document_embeddings): TransformerDocumentEmbeddings(\n","    (model): DistilBertModel(\n","      (embeddings): Embeddings(\n","        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (transformer): Transformer(\n","        (layer): ModuleList(\n","          (0): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (1): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (2): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (3): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (4): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","          (5): TransformerBlock(\n","            (attention): MultiHeadSelfAttention(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","            )\n","            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (ffn): FFN(\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","            )\n","            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (decoder): Linear(in_features=768, out_features=6, bias=True)\n","  (weights): None\n","  (weight_tensor) None\n",")\"\n","2022-01-15 15:39:32,147 ----------------------------------------------------------------------------------------------------\n","2022-01-15 15:39:32,152 Corpus: \"Corpus: 193777 train + 21531 dev + 23923 test sentences\"\n","2022-01-15 15:39:32,154 ----------------------------------------------------------------------------------------------------\n","2022-01-15 15:39:32,155 Parameters:\n","2022-01-15 15:39:32,157  - learning_rate: \"0.1\"\n","2022-01-15 15:39:32,159  - mini_batch_size: \"64\"\n","2022-01-15 15:39:32,161  - patience: \"3\"\n","2022-01-15 15:39:32,162  - anneal_factor: \"0.5\"\n","2022-01-15 15:39:32,164  - max_epochs: \"200\"\n","2022-01-15 15:39:32,166  - shuffle: \"True\"\n","2022-01-15 15:39:32,168  - train_with_dev: \"False\"\n","2022-01-15 15:39:32,169  - batch_growth_annealing: \"False\"\n","2022-01-15 15:39:32,171 ----------------------------------------------------------------------------------------------------\n","2022-01-15 15:39:32,173 Model training base path: \"resources/models\"\n","2022-01-15 15:39:32,175 ----------------------------------------------------------------------------------------------------\n","2022-01-15 15:39:32,177 Device: cuda:0\n","2022-01-15 15:39:32,179 ----------------------------------------------------------------------------------------------------\n","2022-01-15 15:39:32,182 Embeddings storage mode: gpu\n","2022-01-15 15:39:32,185 ----------------------------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 15:41:42,646 epoch 1 - iter 302/3028 - loss 0.01426805 - samples/sec: 149.80 - lr: 0.100000\n","2022-01-15 15:43:56,043 epoch 1 - iter 604/3028 - loss 0.01361410 - samples/sec: 147.23 - lr: 0.100000\n","2022-01-15 15:46:15,750 epoch 1 - iter 906/3028 - loss 0.01298947 - samples/sec: 140.32 - lr: 0.100000\n","2022-01-15 15:48:16,508 epoch 1 - iter 1208/3028 - loss 0.01265048 - samples/sec: 162.50 - lr: 0.100000\n","2022-01-15 15:50:36,723 epoch 1 - iter 1510/3028 - loss 0.01266589 - samples/sec: 139.82 - lr: 0.100000\n","2022-01-15 15:52:43,033 epoch 1 - iter 1812/3028 - loss 0.01265217 - samples/sec: 155.36 - lr: 0.100000\n","2022-01-15 15:54:58,459 epoch 1 - iter 2114/3028 - loss 0.01255182 - samples/sec: 144.71 - lr: 0.100000\n","2022-01-15 15:57:15,585 epoch 1 - iter 2416/3028 - loss 0.01247590 - samples/sec: 143.12 - lr: 0.100000\n","2022-01-15 15:59:19,100 epoch 1 - iter 2718/3028 - loss 0.01245236 - samples/sec: 158.79 - lr: 0.100000\n","2022-01-15 16:01:47,888 epoch 1 - iter 3020/3028 - loss 0.01241310 - samples/sec: 131.71 - lr: 0.100000\n","2022-01-15 16:01:51,928 ----------------------------------------------------------------------------------------------------\n","2022-01-15 16:01:51,931 EPOCH 1 done: loss 0.0124 - lr 0.1000000\n","2022-01-15 16:03:10,244 DEV : loss 0.012216931208968163 - f1-score (micro avg)  0.8568\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 16:04:45,806 TEST : loss 0.012125610373914242 - f1-score (micro avg)  0.8593\n","2022-01-15 16:04:50,479 BAD EPOCHS (no improvement): 0\n","2022-01-15 16:04:50,484 saving best model\n","2022-01-15 16:04:51,174 ----------------------------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 16:07:21,020 epoch 2 - iter 302/3028 - loss 0.01116524 - samples/sec: 131.46 - lr: 0.100000\n","2022-01-15 16:09:47,856 epoch 2 - iter 604/3028 - loss 0.01117882 - samples/sec: 133.36 - lr: 0.100000\n","2022-01-15 16:12:12,460 epoch 2 - iter 906/3028 - loss 0.01116112 - samples/sec: 134.49 - lr: 0.100000\n","2022-01-15 16:14:38,257 epoch 2 - iter 1208/3028 - loss 0.01112284 - samples/sec: 134.32 - lr: 0.100000\n","2022-01-15 16:17:07,591 epoch 2 - iter 1510/3028 - loss 0.01116992 - samples/sec: 131.13 - lr: 0.100000\n","2022-01-15 16:19:33,471 epoch 2 - iter 1812/3028 - loss 0.01115364 - samples/sec: 134.20 - lr: 0.100000\n","2022-01-15 16:22:00,130 epoch 2 - iter 2114/3028 - loss 0.01114855 - samples/sec: 133.49 - lr: 0.100000\n","2022-01-15 16:24:24,761 epoch 2 - iter 2416/3028 - loss 0.01113470 - samples/sec: 135.40 - lr: 0.100000\n","2022-01-15 16:26:51,234 epoch 2 - iter 2718/3028 - loss 0.01112361 - samples/sec: 133.71 - lr: 0.100000\n","2022-01-15 16:29:17,685 epoch 2 - iter 3020/3028 - loss 0.01111568 - samples/sec: 133.71 - lr: 0.100000\n","2022-01-15 16:29:21,894 ----------------------------------------------------------------------------------------------------\n","2022-01-15 16:29:21,896 EPOCH 2 done: loss 0.0111 - lr 0.1000000\n","2022-01-15 16:30:40,293 DEV : loss 0.01153493020683527 - f1-score (micro avg)  0.8644\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 16:32:16,451 TEST : loss 0.01157221570611 - f1-score (micro avg)  0.8664\n","2022-01-15 16:32:21,108 BAD EPOCHS (no improvement): 0\n","2022-01-15 16:32:21,111 saving best model\n","2022-01-15 16:32:21,829 ----------------------------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 16:34:51,305 epoch 3 - iter 302/3028 - loss 0.01001925 - samples/sec: 131.76 - lr: 0.100000\n","2022-01-15 16:37:17,077 epoch 3 - iter 604/3028 - loss 0.01006146 - samples/sec: 133.44 - lr: 0.100000\n","2022-01-15 16:39:44,334 epoch 3 - iter 906/3028 - loss 0.01010944 - samples/sec: 132.97 - lr: 0.100000\n","2022-01-15 16:42:12,662 epoch 3 - iter 1208/3028 - loss 0.01014610 - samples/sec: 132.00 - lr: 0.100000\n","2022-01-15 16:44:39,758 epoch 3 - iter 1510/3028 - loss 0.01020319 - samples/sec: 133.07 - lr: 0.100000\n","2022-01-15 16:47:04,856 epoch 3 - iter 1812/3028 - loss 0.01021261 - samples/sec: 134.97 - lr: 0.100000\n","2022-01-15 16:49:32,733 epoch 3 - iter 2114/3028 - loss 0.01023451 - samples/sec: 132.37 - lr: 0.100000\n","2022-01-15 16:52:02,201 epoch 3 - iter 2416/3028 - loss 0.01025474 - samples/sec: 131.00 - lr: 0.100000\n","2022-01-15 16:54:26,048 epoch 3 - iter 2718/3028 - loss 0.01026237 - samples/sec: 136.17 - lr: 0.100000\n","2022-01-15 16:56:50,255 epoch 3 - iter 3020/3028 - loss 0.01029837 - samples/sec: 135.80 - lr: 0.100000\n","2022-01-15 16:56:54,340 ----------------------------------------------------------------------------------------------------\n","2022-01-15 16:56:54,342 EPOCH 3 done: loss 0.0103 - lr 0.1000000\n","2022-01-15 16:58:11,818 DEV : loss 0.011341338977217674 - f1-score (micro avg)  0.8687\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 16:59:46,485 TEST : loss 0.011206299997866154 - f1-score (micro avg)  0.8704\n","2022-01-15 16:59:51,194 BAD EPOCHS (no improvement): 0\n","2022-01-15 16:59:51,197 saving best model\n","2022-01-15 16:59:51,904 ----------------------------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 17:02:18,882 epoch 4 - iter 302/3028 - loss 0.00917242 - samples/sec: 133.93 - lr: 0.100000\n","2022-01-15 17:04:47,312 epoch 4 - iter 604/3028 - loss 0.00936963 - samples/sec: 132.58 - lr: 0.100000\n","2022-01-15 17:07:15,300 epoch 4 - iter 906/3028 - loss 0.00944635 - samples/sec: 132.33 - lr: 0.100000\n","2022-01-15 17:09:44,150 epoch 4 - iter 1208/3028 - loss 0.00950789 - samples/sec: 131.56 - lr: 0.100000\n","2022-01-15 17:12:10,078 epoch 4 - iter 1510/3028 - loss 0.00958268 - samples/sec: 134.21 - lr: 0.100000\n","2022-01-15 17:14:35,775 epoch 4 - iter 1812/3028 - loss 0.00959520 - samples/sec: 134.36 - lr: 0.100000\n","2022-01-15 17:17:03,784 epoch 4 - iter 2114/3028 - loss 0.00963258 - samples/sec: 132.32 - lr: 0.100000\n","2022-01-15 17:19:33,579 epoch 4 - iter 2416/3028 - loss 0.00965696 - samples/sec: 130.71 - lr: 0.100000\n","2022-01-15 17:22:01,363 epoch 4 - iter 2718/3028 - loss 0.00969381 - samples/sec: 132.50 - lr: 0.100000\n","2022-01-15 17:24:27,845 epoch 4 - iter 3020/3028 - loss 0.00972470 - samples/sec: 133.70 - lr: 0.100000\n","2022-01-15 17:24:32,171 ----------------------------------------------------------------------------------------------------\n","2022-01-15 17:24:32,178 EPOCH 4 done: loss 0.0097 - lr 0.1000000\n","2022-01-15 17:25:50,464 DEV : loss 0.011244130320847034 - f1-score (micro avg)  0.8695\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 17:27:24,776 TEST : loss 0.011281082406640053 - f1-score (micro avg)  0.8697\n","2022-01-15 17:27:29,497 BAD EPOCHS (no improvement): 0\n","2022-01-15 17:27:29,500 saving best model\n","2022-01-15 17:27:30,273 ----------------------------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 17:30:01,054 epoch 5 - iter 302/3028 - loss 0.00880357 - samples/sec: 130.62 - lr: 0.100000\n","2022-01-15 17:32:28,393 epoch 5 - iter 604/3028 - loss 0.00892521 - samples/sec: 132.91 - lr: 0.100000\n","2022-01-15 17:34:55,603 epoch 5 - iter 906/3028 - loss 0.00898624 - samples/sec: 133.04 - lr: 0.100000\n","2022-01-15 17:37:23,360 epoch 5 - iter 1208/3028 - loss 0.00905143 - samples/sec: 132.53 - lr: 0.100000\n","2022-01-15 17:39:50,384 epoch 5 - iter 1510/3028 - loss 0.00908868 - samples/sec: 133.20 - lr: 0.100000\n","2022-01-15 17:42:18,725 epoch 5 - iter 1812/3028 - loss 0.00913634 - samples/sec: 132.00 - lr: 0.100000\n","2022-01-15 17:44:47,956 epoch 5 - iter 2114/3028 - loss 0.00917854 - samples/sec: 131.22 - lr: 0.100000\n","2022-01-15 17:47:14,116 epoch 5 - iter 2416/3028 - loss 0.00921323 - samples/sec: 134.31 - lr: 0.100000\n","2022-01-15 17:49:41,799 epoch 5 - iter 2718/3028 - loss 0.00924930 - samples/sec: 133.37 - lr: 0.100000\n","2022-01-15 17:52:06,108 epoch 5 - iter 3020/3028 - loss 0.00927785 - samples/sec: 134.76 - lr: 0.100000\n","2022-01-15 17:52:10,260 ----------------------------------------------------------------------------------------------------\n","2022-01-15 17:52:10,261 EPOCH 5 done: loss 0.0093 - lr 0.1000000\n","2022-01-15 17:53:29,461 DEV : loss 0.011735530570149422 - f1-score (micro avg)  0.8687\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 17:55:02,451 TEST : loss 0.011715706437826157 - f1-score (micro avg)  0.8702\n","2022-01-15 17:55:07,049 BAD EPOCHS (no improvement): 1\n","2022-01-15 17:55:07,052 ----------------------------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 17:57:33,567 epoch 6 - iter 302/3028 - loss 0.00815465 - samples/sec: 134.53 - lr: 0.100000\n","2022-01-15 17:59:58,968 epoch 6 - iter 604/3028 - loss 0.00830543 - samples/sec: 134.72 - lr: 0.100000\n","2022-01-15 18:02:26,721 epoch 6 - iter 906/3028 - loss 0.00837831 - samples/sec: 132.51 - lr: 0.100000\n","2022-01-15 18:04:54,077 epoch 6 - iter 1208/3028 - loss 0.00848846 - samples/sec: 132.89 - lr: 0.100000\n","2022-01-15 18:07:19,373 epoch 6 - iter 1510/3028 - loss 0.00857434 - samples/sec: 134.78 - lr: 0.100000\n","2022-01-15 18:09:47,696 epoch 6 - iter 1812/3028 - loss 0.00862499 - samples/sec: 132.00 - lr: 0.100000\n","2022-01-15 18:12:13,811 epoch 6 - iter 2114/3028 - loss 0.00867792 - samples/sec: 133.05 - lr: 0.100000\n","2022-01-15 18:14:40,467 epoch 6 - iter 2416/3028 - loss 0.00872140 - samples/sec: 133.51 - lr: 0.100000\n","2022-01-15 18:17:09,573 epoch 6 - iter 2718/3028 - loss 0.00878606 - samples/sec: 131.26 - lr: 0.100000\n","2022-01-15 18:19:36,081 epoch 6 - iter 3020/3028 - loss 0.00882175 - samples/sec: 133.63 - lr: 0.100000\n","2022-01-15 18:19:39,989 ----------------------------------------------------------------------------------------------------\n","2022-01-15 18:19:39,990 EPOCH 6 done: loss 0.0088 - lr 0.1000000\n","2022-01-15 18:20:58,064 DEV : loss 0.011861302889883518 - f1-score (micro avg)  0.8646\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["2022-01-15 18:22:34,006 TEST : loss 0.011860143393278122 - f1-score (micro avg)  0.867\n","2022-01-15 18:22:38,525 BAD EPOCHS (no improvement): 2\n","2022-01-15 18:22:38,527 ----------------------------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 18:25:04,474 epoch 7 - iter 302/3028 - loss 0.00769180 - samples/sec: 134.98 - lr: 0.100000\n","2022-01-15 18:27:31,196 epoch 7 - iter 604/3028 - loss 0.00782302 - samples/sec: 133.51 - lr: 0.100000\n","2022-01-15 18:29:56,654 epoch 7 - iter 906/3028 - loss 0.00796350 - samples/sec: 134.66 - lr: 0.100000\n","2022-01-15 18:32:23,094 epoch 7 - iter 1208/3028 - loss 0.00803268 - samples/sec: 133.69 - lr: 0.100000\n","2022-01-15 18:34:48,501 epoch 7 - iter 1510/3028 - loss 0.00812309 - samples/sec: 134.71 - lr: 0.100000\n","2022-01-15 18:37:14,291 epoch 7 - iter 1812/3028 - loss 0.00819537 - samples/sec: 133.36 - lr: 0.100000\n","2022-01-15 18:39:41,310 epoch 7 - iter 2114/3028 - loss 0.00825397 - samples/sec: 133.17 - lr: 0.100000\n","2022-01-15 18:42:07,634 epoch 7 - iter 2416/3028 - loss 0.00832276 - samples/sec: 133.82 - lr: 0.100000\n","2022-01-15 18:44:35,332 epoch 7 - iter 2718/3028 - loss 0.00838033 - samples/sec: 132.59 - lr: 0.100000\n","2022-01-15 18:47:03,694 epoch 7 - iter 3020/3028 - loss 0.00842240 - samples/sec: 131.92 - lr: 0.100000\n","2022-01-15 18:47:07,560 ----------------------------------------------------------------------------------------------------\n","2022-01-15 18:47:07,568 EPOCH 7 done: loss 0.0084 - lr 0.1000000\n","2022-01-15 18:48:25,455 DEV : loss 0.01238635741174221 - f1-score (micro avg)  0.8676\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 18:50:00,920 TEST : loss 0.012346530333161354 - f1-score (micro avg)  0.8676\n","2022-01-15 18:50:05,525 BAD EPOCHS (no improvement): 3\n","2022-01-15 18:50:05,528 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 18:52:33,597 epoch 8 - iter 302/3028 - loss 0.00738119 - samples/sec: 133.11 - lr: 0.100000\n","2022-01-15 18:55:01,840 epoch 8 - iter 604/3028 - loss 0.00746747 - samples/sec: 132.09 - lr: 0.100000\n","2022-01-15 18:57:27,055 epoch 8 - iter 906/3028 - loss 0.00763078 - samples/sec: 133.89 - lr: 0.100000\n","2022-01-15 18:59:54,454 epoch 8 - iter 1208/3028 - loss 0.00769102 - samples/sec: 132.83 - lr: 0.100000\n","2022-01-15 19:02:19,633 epoch 8 - iter 1510/3028 - loss 0.00777644 - samples/sec: 134.88 - lr: 0.100000\n","2022-01-15 19:04:48,428 epoch 8 - iter 1812/3028 - loss 0.00782702 - samples/sec: 131.57 - lr: 0.100000\n","2022-01-15 19:07:13,899 epoch 8 - iter 2114/3028 - loss 0.00788548 - samples/sec: 134.57 - lr: 0.100000\n","2022-01-15 19:09:40,248 epoch 8 - iter 2416/3028 - loss 0.00793043 - samples/sec: 133.80 - lr: 0.100000\n","2022-01-15 19:12:05,469 epoch 8 - iter 2718/3028 - loss 0.00797867 - samples/sec: 134.86 - lr: 0.100000\n","2022-01-15 19:14:31,813 epoch 8 - iter 3020/3028 - loss 0.00803086 - samples/sec: 133.77 - lr: 0.100000\n","2022-01-15 19:14:35,929 ----------------------------------------------------------------------------------------------------\n","2022-01-15 19:14:35,930 EPOCH 8 done: loss 0.0080 - lr 0.1000000\n","2022-01-15 19:15:53,858 DEV : loss 0.013323348015546799 - f1-score (micro avg)  0.8586\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 19:17:29,433 TEST : loss 0.013311274349689484 - f1-score (micro avg)  0.8593\n","Epoch     8: reducing learning rate of group 0 to 5.0000e-02.\n","2022-01-15 19:17:34,011 BAD EPOCHS (no improvement): 4\n","2022-01-15 19:17:34,017 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 19:20:03,574 epoch 9 - iter 302/3028 - loss 0.00630287 - samples/sec: 131.75 - lr: 0.050000\n","2022-01-15 19:22:29,185 epoch 9 - iter 604/3028 - loss 0.00616996 - samples/sec: 133.54 - lr: 0.050000\n","2022-01-15 19:24:54,999 epoch 9 - iter 906/3028 - loss 0.00621755 - samples/sec: 134.31 - lr: 0.050000\n","2022-01-15 19:27:20,165 epoch 9 - iter 1208/3028 - loss 0.00623237 - samples/sec: 134.87 - lr: 0.050000\n","2022-01-15 19:29:45,036 epoch 9 - iter 1510/3028 - loss 0.00623938 - samples/sec: 135.22 - lr: 0.050000\n","2022-01-15 19:32:10,794 epoch 9 - iter 1812/3028 - loss 0.00626052 - samples/sec: 134.35 - lr: 0.050000\n","2022-01-15 19:34:39,401 epoch 9 - iter 2114/3028 - loss 0.00628045 - samples/sec: 131.72 - lr: 0.050000\n","2022-01-15 19:37:04,417 epoch 9 - iter 2416/3028 - loss 0.00627725 - samples/sec: 135.01 - lr: 0.050000\n","2022-01-15 19:39:32,509 epoch 9 - iter 2718/3028 - loss 0.00629069 - samples/sec: 132.21 - lr: 0.050000\n","2022-01-15 19:42:00,983 epoch 9 - iter 3020/3028 - loss 0.00629865 - samples/sec: 131.88 - lr: 0.050000\n","2022-01-15 19:42:05,483 ----------------------------------------------------------------------------------------------------\n","2022-01-15 19:42:05,485 EPOCH 9 done: loss 0.0063 - lr 0.0500000\n","2022-01-15 19:43:22,961 DEV : loss 0.014154999516904354 - f1-score (micro avg)  0.86\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 19:44:58,612 TEST : loss 0.014267581515014172 - f1-score (micro avg)  0.8615\n","2022-01-15 19:45:03,095 BAD EPOCHS (no improvement): 1\n","2022-01-15 19:45:03,097 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 19:47:28,059 epoch 10 - iter 302/3028 - loss 0.00489844 - samples/sec: 134.82 - lr: 0.050000\n","2022-01-15 19:49:55,675 epoch 10 - iter 604/3028 - loss 0.00504144 - samples/sec: 132.80 - lr: 0.050000\n","2022-01-15 19:52:22,591 epoch 10 - iter 906/3028 - loss 0.00511457 - samples/sec: 133.31 - lr: 0.050000\n","2022-01-15 19:54:50,557 epoch 10 - iter 1208/3028 - loss 0.00515403 - samples/sec: 132.29 - lr: 0.050000\n","2022-01-15 19:57:17,540 epoch 10 - iter 1510/3028 - loss 0.00523943 - samples/sec: 133.22 - lr: 0.050000\n","2022-01-15 19:59:43,135 epoch 10 - iter 1812/3028 - loss 0.00531440 - samples/sec: 134.48 - lr: 0.050000\n","2022-01-15 20:02:09,397 epoch 10 - iter 2114/3028 - loss 0.00536337 - samples/sec: 133.87 - lr: 0.050000\n","2022-01-15 20:04:35,694 epoch 10 - iter 2416/3028 - loss 0.00542844 - samples/sec: 133.89 - lr: 0.050000\n","2022-01-15 20:07:02,409 epoch 10 - iter 2718/3028 - loss 0.00547462 - samples/sec: 133.46 - lr: 0.050000\n","2022-01-15 20:09:29,665 epoch 10 - iter 3020/3028 - loss 0.00551981 - samples/sec: 132.94 - lr: 0.050000\n","2022-01-15 20:09:33,787 ----------------------------------------------------------------------------------------------------\n","2022-01-15 20:09:33,789 EPOCH 10 done: loss 0.0055 - lr 0.0500000\n","2022-01-15 20:10:51,326 DEV : loss 0.015640636906027794 - f1-score (micro avg)  0.8629\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 20:12:24,815 TEST : loss 0.015567264519631863 - f1-score (micro avg)  0.8627\n","2022-01-15 20:12:29,388 BAD EPOCHS (no improvement): 2\n","2022-01-15 20:12:29,392 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 20:14:59,567 epoch 11 - iter 302/3028 - loss 0.00440477 - samples/sec: 131.05 - lr: 0.050000\n","2022-01-15 20:17:27,139 epoch 11 - iter 604/3028 - loss 0.00452324 - samples/sec: 132.77 - lr: 0.050000\n","2022-01-15 20:19:52,350 epoch 11 - iter 906/3028 - loss 0.00458480 - samples/sec: 134.83 - lr: 0.050000\n","2022-01-15 20:22:18,974 epoch 11 - iter 1208/3028 - loss 0.00466026 - samples/sec: 133.54 - lr: 0.050000\n","2022-01-15 20:24:46,661 epoch 11 - iter 1510/3028 - loss 0.00469932 - samples/sec: 132.60 - lr: 0.050000\n","2022-01-15 20:27:11,952 epoch 11 - iter 1812/3028 - loss 0.00475006 - samples/sec: 134.82 - lr: 0.050000\n","2022-01-15 20:29:38,758 epoch 11 - iter 2114/3028 - loss 0.00479826 - samples/sec: 133.39 - lr: 0.050000\n","2022-01-15 20:32:04,770 epoch 11 - iter 2416/3028 - loss 0.00486839 - samples/sec: 134.11 - lr: 0.050000\n","2022-01-15 20:34:32,081 epoch 11 - iter 2718/3028 - loss 0.00491679 - samples/sec: 132.53 - lr: 0.050000\n","2022-01-15 20:36:58,462 epoch 11 - iter 3020/3028 - loss 0.00496518 - samples/sec: 133.82 - lr: 0.050000\n","2022-01-15 20:37:02,738 ----------------------------------------------------------------------------------------------------\n","2022-01-15 20:37:02,745 EPOCH 11 done: loss 0.0050 - lr 0.0500000\n","2022-01-15 20:38:21,992 DEV : loss 0.016787493601441383 - f1-score (micro avg)  0.8598\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 20:39:55,146 TEST : loss 0.01693682372570038 - f1-score (micro avg)  0.8606\n","2022-01-15 20:39:59,769 BAD EPOCHS (no improvement): 3\n","2022-01-15 20:39:59,773 ----------------------------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["2022-01-15 20:42:25,771 epoch 12 - iter 302/3028 - loss 0.00393933 - samples/sec: 135.01 - lr: 0.050000\n","2022-01-15 20:44:53,336 epoch 12 - iter 604/3028 - loss 0.00400897 - samples/sec: 132.68 - lr: 0.050000\n","2022-01-15 20:47:20,444 epoch 12 - iter 906/3028 - loss 0.00411207 - samples/sec: 133.17 - lr: 0.050000\n","2022-01-15 20:49:46,222 epoch 12 - iter 1208/3028 - loss 0.00422020 - samples/sec: 134.30 - lr: 0.050000\n"]}]},{"cell_type":"markdown","source":["# Results"],"metadata":{"id":"Z3yOiDK8ZglP"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjOTIB6GkNUQ","executionInfo":{"status":"ok","timestamp":1630160733015,"user_tz":-180,"elapsed":410,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"01844dd6-266d-479d-b11d-79ab7112fd71"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["resources  sample_data\ttrain.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TQ2QmM6Jr5m","executionInfo":{"status":"ok","timestamp":1630160767127,"user_tz":-180,"elapsed":763,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"580a25ff-3834-4dd3-af58-da1423b6ab52"},"source":["!ls -l resources"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 4\n","drwxr-xr-x 2 root root 4096 Aug 28 11:57 models\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJNErP_NJwek","executionInfo":{"status":"ok","timestamp":1630160776120,"user_tz":-180,"elapsed":404,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"498f02ef-d6e7-46a0-bb47-4efa7f872e2c"},"source":["!ls -l resources/models"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total 1501016\n","-rw-r--r-- 1 root root 768365732 Aug 28 12:17 best-model.pt\n","-rw-r--r-- 1 root root     84984 Aug 28 13:49 dev.tsv\n","-rw-r--r-- 1 root root 768365732 Aug 28 13:49 final-model.pt\n","-rw-r--r-- 1 root root      5863 Aug 28 13:49 loss.tsv\n","-rw-r--r-- 1 root root     94672 Aug 28 13:50 test.tsv\n","-rw-r--r-- 1 root root     95824 Aug 28 13:50 training.log\n","-rw-r--r-- 1 root root         0 Aug 28 11:55 weights.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VbPaoPhVJyLP","executionInfo":{"status":"ok","timestamp":1630160890029,"user_tz":-180,"elapsed":98821,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"6fb47baa-94ea-4a7f-c3fd-b386991d9027"},"source":["!zip -r model.zip resources/models"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  adding: resources/models/ (stored 0%)\n","  adding: resources/models/best-model.pt (deflated 13%)\n","  adding: resources/models/weights.txt (stored 0%)\n","  adding: resources/models/training.log (deflated 82%)\n","  adding: resources/models/test.tsv (deflated 56%)\n","  adding: resources/models/loss.tsv (deflated 56%)\n","  adding: resources/models/final-model.pt (deflated 13%)\n","  adding: resources/models/dev.tsv (deflated 56%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIEukxZIVSLd","executionInfo":{"status":"ok","timestamp":1630163814334,"user_tz":-180,"elapsed":24195,"user":{"displayName":"Mykola Haltiuk","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-HTQlMcjXv5Ignw-w0XJXyYUpITi6vgcq2zhzOg=s64","userId":"08555164971466863527"}},"outputId":"264d852d-4969-4245-cf5d-346e942fcfa1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cHLFFgjtKV7M"},"source":["!cp model.zip /content/drive/MyDrive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wi3MYI0VFL9"},"source":[""],"execution_count":null,"outputs":[]}]}